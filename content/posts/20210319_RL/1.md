---
title: "強化学習とは"
date: 2021-03-18T18:00:23+09:00
draft: false
tags: ["強化学習"] 
---
<!--more-->
# 強化学習とは

## 機械学習の用語整理

機械学習における「**モデル**」とは、データから学習する数式やアルゴリズムのことで、その内部には調整可能な「**パラメータ**」を持っています。このパラメータを、与えられたデータに基づいて最適化するプロセスを「**学習**」または「**訓練**」と呼びます。

モデルの一種として、人間の脳の神経回路を模倣した「**ニューラルネットワーク (NN)**」があり、これを多層にしたものが「**ディープニューラルネットワーク (DNN)**」です。

学習の手法は大きく分けて以下の3つがあります。

-   **教師あり学習 (Supervised Learning)**
-   **教師なし学習 (Unsupervised Learning)**
-   **強化学習 (Reinforcement Learning)**

## 強化学習の概要

強化学習は、教師あり学習や教師なし学習のようにデータセットが与えられるのではなく、「**環境**」が与えられる点が特徴です。

-   **環境**: エージェント（学習主体）が行動し、その行動に応じて状態が変化し、特定の状態に到達したり、特定の行動を取ったりすることで「報酬」が与えられる空間のことです。

強化学習では、エージェントが環境と相互作用しながら、より多くの報酬を獲得できるようにモデルのパラメータを調整します。環境の開始から終了までの一連の行動と状態の遷移を「**1エピソード**」と呼び、この1エピソードで得られる**累積報酬を最大化**することが学習の目的となります。

## 問題設定：マルコフ決定過程 (MDP)

強化学習の問題は、多くの場合、**マルコフ決定過程 (Markov Decision Process, MDP)** として定式化されます。MDPは、**マルコフ性**（次の状態が現在の状態と行動のみに依存し、過去の履歴には依存しない性質）を持つ意思決定過程です。

MDPの主要な構成要素は以下の4つです。

-   $S$: **状態 (State)** の集合。エージェントが現在置かれている状況を表します。
-   $A$: **行動 (Action)** の集合。エージェントが各状態で取りうる選択肢です。
-   $T$: **状態遷移確率 (Transition Probability)**。現在の状態 $s$ で行動 $a$ を取ったときに、次の状態 $s'$ へ遷移する確率 $P(s'|s, a)$ を表します。
-   $R$: **報酬関数 (Reward Function)**。ある状態 $s$ で行動 $a$ を取り、次の状態 $s'$ に遷移したときに得られる報酬 $R(s, a, s')$ を表します。

強化学習における「ロボット」や「AI」は、これらの状態を受け取り、最適な行動を出力する関数とみなすことができます。この関数のことを「**方策 (Policy)**」 $\pi(a|s)$ と呼びます。エージェントは、報酬を最大化するように方策を更新していくことで、最適な方策を発見することを目指します。

## 参考
-   久保隆宏, 『Pythonで学ぶ強化学習 入門から実践まで』, 翔泳社 (2019)