---
title: "ラグランジュの未定乗数法"
date: 2021-03-16T15:00:23+09:00
draft: false
tags: ["数学", "最適化"] 
---
<!--more-->
# ラグランジュの未定乗数法

ラグランジュの未定乗数法（Lagrange Multiplier Method）は、**等式制約**の下で多変数関数の最大値や最小値を求めるための強力な数学的手法です。

## 原理

目的関数 $f(x, y)$ を、制約条件 $g(x, y) = 0$ の下で最適化する問題を考えます。
最適解となる点では、目的関数の等高線と制約条件の曲線が接します。このとき、両者の勾配ベクトルは平行になります。

勾配ベクトルは、関数が最も急峻に変化する方向を示し、勾配作用素 $\nabla$ を用いて以下のように定義されます。
$$ \nabla f = \left(\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}\right) $$

したがって、最適解の点では、以下の関係が成り立ちます。
$$ \nabla f(x, y) = \lambda \nabla g(x, y) $$
ここで $\lambda$ は**ラグランジュ乗数（Lagrange Multiplier）**と呼ばれる定数です。

この関係式と制約条件 $g(x, y) = 0$ を連立して解くことで、最適解の候補となる点を見つけることができます。

## ラグランジュ関数

ラグランジュの未定乗数法は、以下の**ラグランジュ関数** $\mathcal{L}(x, y, \lambda)$ を導入することで、制約付き最適化問題を制約なし最適化問題に変換します。

$$ \mathcal{L}(x, y, \lambda) = f(x, y) - \lambda g(x, y) $$

このラグランジュ関数を各変数（$x, y, \lambda$）で偏微分し、それぞれを0と置くことで、最適解の候補を求めることができます。

$$ \frac{\partial \mathcal{L}}{\partial x} = 0 $$
$$ \frac{\partial \mathcal{L}}{\partial y} = 0 $$
$$ \frac{\partial \mathcal{L}}{\partial \lambda} = 0 $$

最後の式 $\frac{\partial \mathcal{L}}{\partial \lambda} = -g(x, y) = 0$ は、元の制約条件 $g(x, y) = 0$ そのものです。

### 例題

制約条件 $2x + y + 1 = 0$ の下で、関数 $f(x, y) = x^2 + y^2$ を最小化する $x, y$ を求めます。

ラグランジュ関数は、
$$ \mathcal{L}(x, y, \lambda) = x^2 + y^2 - \lambda (2x + y + 1) $$

各変数で偏微分し、0と置きます。
1.  $\frac{\partial \mathcal{L}}{\partial x} = 2x - 2\lambda = 0 \implies x = \lambda$
2.  $\frac{\partial \mathcal{L}}{\partial y} = 2y - \lambda = 0 \implies y = \frac{1}{2}\lambda$
3.  $\frac{\partial \mathcal{L}}{\partial \lambda} = -(2x + y + 1) = 0 \implies 2x + y + 1 = 0$

1と2の式を3の式に代入すると、
$2(\lambda) + (\frac{1}{2}\lambda) + 1 = 0$
$\frac{5}{2}\lambda = -1$
$\lambda = -\frac{2}{5}$

これを $x = \lambda$ と $y = \frac{1}{2}\lambda$ に代入すると、
$x = -\frac{2}{5}$
$y = -\frac{1}{5}$

したがって、制約条件の下で $f(x, y)$ を最小化する点は $(-\frac{2}{5}, -\frac{1}{5})$ となります。

## 多項分布の最尤推定への応用

多項分布の最尤推定では、確率の総和が1になるという制約条件の下で、対数尤度関数を最大化する必要があります。このような場合にラグランジュの未定乗数法が有効です。

多項分布の確率質量関数は、各カテゴリの出現回数を $x_j$、各カテゴリの出現確率を $\mu_j$ とすると、
$$ p(x_1, \dots, x_k | \mu_1, \dots, \mu_k) = \frac{(\sum x_j)!}{\prod x_j!} \prod_{j=1}^k \mu_j^{x_j} $$
対数尤度関数は、定数項を除くと $\sum_{j=1}^k x_j \log \mu_j$ となります。
制約条件は $\sum_{j=1}^k \mu_j - 1 = 0$ です。

ラグランジュ関数は、
$$ \mathcal{L}(\mu_1, \dots, \mu_k, \lambda) = \sum_{j=1}^k x_j \log \mu_j - \lambda \left(\sum_{j=1}^k \mu_j - 1\right) $$

これを $\mu_h$ で偏微分し、0と置きます。
$$ \frac{\partial \mathcal{L}}{\partial \mu_h} = \frac{x_h}{\mu_h} - \lambda = 0 \implies \mu_h = \frac{x_h}{\lambda} $$

全ての $h$ について $\mu_h = x_h / \lambda$ が成り立つので、これを制約条件 $\sum_{j=1}^k \mu_j = 1$ に代入します。
$$ \sum_{j=1}^k \frac{x_j}{\lambda} = 1 \implies \frac{1}{\lambda} \sum_{j=1}^k x_j = 1 $$
ここで $\sum_{j=1}^k x_j = m$ は総試行回数なので、
$$ \frac{m}{\lambda} = 1 \implies \lambda = m $$

したがって、多項分布の各カテゴリの確率 $\mu_j$ の最尤推定量は、
$$ \hat{\mu}_j = \frac{x_j}{m} $$
となります。これは、各カテゴリの出現回数を総試行回数で割った、直感的な頻度と一致します。

## 参考
-   手塚 太郎, 『しくみがわかるベイズ統計と機械学習』, 講談社 (2017)