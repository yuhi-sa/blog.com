---
title: "ガウス分布間クロスエントロピーの閉形式解の数理導出"
date: 2021-12-09T11:00:23+09:00
draft: false
description: "2つのガウス分布間のクロスエントロピーを閉形式で導出する数学的手順を、期待値と分散の性質を用いてステップごとに解説します。"
tags: ["機械学習", "数理"]
keywords: ["機械学習", "数理"]
---

<!--more-->

ここでは、2つのガウス分布 $p_1(x)$ と $p_2(x)$ の間のクロスエントロピー $H(p_1, p_2)$ を閉形式で導出します。

## 準備

### ガウス分布 (正規分布)

平均 $\mu$、分散 $\sigma^2$ のガウス分布の確率密度関数は次の通りです。

$$ p(x | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\lbrace-\frac{(x-\mu)^2}{2\sigma^2}\rbrace $$

### 期待値と分散の性質

確率変数 $X$ がガウス分布に従うとき、

- 期待値: $\mathbb{E}[X] = \mu$
- 分散: $\mathbb{V}[X] = \mathbb{E}[X^2] - (\mathbb{E}[X])^2 = \sigma^2$
- したがって、$\mathbb{E}[X^2] = \mu^2 + \sigma^2$

## クロスエントロピーの導出

2つのガウス分布 $p_1(x) = \mathcal{N}(x | \mu_1, \sigma_1^2)$ と $p_2(x) = \mathcal{N}(x | \mu_2, \sigma_2^2)$ の間のクロスエントロピー $H(p_1, p_2)$ は、以下のように定義されます。

$$ H(p*1, p_2) = -\int*{-\infty}^{\infty} p*1(x) \log p_2(x) dx = -\mathbb{E}*{p_1}[\log p_2(x)] $$

ここで、$\log p_2(x)$ は以下のようになります。

$$ \log p_2(x) = \log (\frac{1}{\sqrt{2\pi\sigma_2^2}} \exp\lbrace-\frac{(x-\mu_2)^2}{2\sigma_2^2}\rbrace) $$
$$ = -\frac{1}{2} \log(2\pi\sigma_2^2) - \frac{(x-\mu_2)^2}{2\sigma_2^2} $$

これを期待値の式に代入します。

$$ H(p*1, p_2) = -\mathbb{E}*{p*1}[-\frac{1}{2} \log(2\pi\sigma_2^2) - \frac{(x-\mu_2)^2}{2\sigma_2^2}] $$
$$ = \frac{1}{2} \log(2\pi\sigma_2^2) + \frac{1}{2\sigma_2^2} \mathbb{E}*{p_1}[(x-\mu_2)^2] $$

ここで、$\mathbb{E}_{p_1}[(x-\mu_2)^2]$ を展開します。

$$ \mathbb{E}_{p_1}[(x-\mu_2)^2] = \mathbb{E}_{p*1}[x^2 - 2x\mu_2 + \mu_2^2] $$
$$ = \mathbb{E}*{p*1}[x^2] - 2\mu_2 \mathbb{E}*{p_1}[x] + \mu_2^2 $$

$p_1(x)$ は平均 $\mu_1$、分散 $\sigma_1^2$ のガウス分布なので、$\mathbb{E}_{p_1}[x] = \mu_1$ および $\mathbb{E}_{p_1}[x^2] = \mu_1^2 + \sigma_1^2$ を代入します。

$$ \mathbb{E}\_{p_1}[(x-\mu_2)^2] = (\mu_1^2 + \sigma_1^2) - 2\mu_2 \mu_1 + \mu_2^2 $$
$$ = (\mu_1 - \mu_2)^2 + \sigma_1^2 $$

これを元のクロスエントロピーの式に代入すると、

$$ H(p_1, p_2) = \frac{1}{2} \log(2\pi\sigma_2^2) + \frac{(\mu_1 - \mu_2)^2 + \sigma_1^2}{2\sigma_2^2} $$

これが、2つのガウス分布間のクロスエントロピーの閉形式表現です。
